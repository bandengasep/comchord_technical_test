Code Review Weekly Workshop - Sep 23, 2022
 Transcribed by TurboScribe.ai. Go Unlimited to remove this message. 
[Speaker 1] (0:01 - 3:21)
All right. Thanks for joining us on the Code Review Weekly Workshop. Since I have the first item on the agenda, I'll share my screen.

And by first item, I mean the only item. And I wanted to share this kind of an update to a MR that we approached earlier in the Code Review Weekly Workshop. This MR was doing something really interesting where we were trying to fix this flashing issue with the drawer component on Safari.

It was like edge case browser specific weird stuff. I don't know if you remember this. But the proposed fix was adding this, which is also like, man, this is real kind of we're knee deep in trying to figure out how we can get things just working.

And it's strange that we'd have to add this is a little bit of a hacky line. But if we need it, we need it. So I do feel like approaching this MR could have taken two different paths.

One is just, well, it looks like this works. Let's merge it. But this does seem strange.

So I feel like it was at least worth asking a question. And Simon directly addressed my question. I was like, okay, that's great.

And so then I was ready to merge this, but I just wanted to test it all out in an integration. Just doing a smoke test of loading our updated GitLab UI package locally. Would this affect existing drawers?

And so like worst case situation is, you know, we make the drawer situation worse. And luckily I went through that process because I did run into, wow, for some reason this is causing an unrelated like styling issue with drawers, where when you have that translate thing, you see it adds this scroll bar to the bottom. And so it creates, and this is happening for all browsers, not just Safari.

So sometimes when we do these hacky things, it's worth considering what's the worst case situation that can happen and just testing it out. Because when we don't totally understand what's the change we're making, sometimes there's unintended side effects and those things pay off. And even if I didn't catch anything, chances are, you know, just getting in that habit and that discipline is worth it as well.

Because when there is an issue, ideally we catch it before users start seeing it. So I thought this was interesting development in this MR. I just wanted to encourage everybody, it pays off to smoke test things. Yeah, definitely.

Very good point. Yeah. Yeah.

Does anyone have any questions or thoughts that they'd want to add on this topic or something else?

[Speaker 2] (3:23 - 3:42)
I actually wonder what's going to happen next with this particular piece of work slash issue. And on this particular PR, what happened? Like after you said, okay, this does not fix anything, it actually causes another issue.

What happens to this particular PR?

[Speaker 1] (3:43 - 5:34)
That's a really good question. So I think I kind of just pass it off back to Simon. And so this does fix the Safari issue, but it does seem like it introduces a new issue.

And now, at one level, we would decide, is fixing the Safari issue worth introducing this new one? Based on severity of the new one, severity of the Safari one, and by severity, those are very soft, fuzzy words. But then I think now Simon's going to, if he wants to tackle this, he will either, A, need to think of another approach.

Or B, just close this MR if he can't get to it anymore. So that'll happen. And we'll probably update with the issue of like, we tried this, but this has other issues, so it doesn't work.

Chances are there might be some sort of other hacky thing we could add on top of TranslateZ. We need TranslateZ for some sort of weird Safari reason, but to stop it from doing these other things, we'll add more rules onto it. So chances are that's an approach that could be taken.

But now it is kind of in the balancing game of the amount of, because these are kind of maintainability costs, the hacks that we're adding. And so the amount of costs we want to take for this approach is interesting. But yeah, it's not great.

It doesn't look great for GitLab when you do have just a, by default, Safari user running into issues like this. It is on Simon's plate, so I'm curious to see what he thinks. That's a good question.

[Speaker 2] (5:35 - 5:45)
Another question. Before this came to review, was this QA'd beforehand?

[Speaker 1] (5:49 - 7:51)
Was this tested locally or when you say QA'd? That's a really good question. Usually, MR authors will do a level of self-testing.

And I think it was probably just tested in this context. But at the same time, too, as an author, self-testing your own stuff is always, even for myself, for everybody, there's blind spots, too. I wrote the code and now I'm testing it.

You're just going to overlook, for some reason, you end up just, it helps to have the impartial viewer run through it, whoever that is. And so QA is a really great term to throw around because who is responsible for that? And I think we do expect a level, like you see these screenshots that Simon included, so there is a level of QA that happened here.

But how far does that need to go is a really great question. And this touches drawers, so I would say anything that touches a drawer, it's worth just smoke testing it. Does this look okay?

And when I say drawer, that's just a GitLab UI component. And so it's really on the reviewer side, too. We review the code, but also the functional integrity of it as well.

So we don't have, in the spirit of keeping our team lean, we don't really have manual testers that are, and that's kind of, we take on the mantle of being third-party experts that can do the exploratory testing to reveal issues if there are any.

[Speaker 2] (7:55 - 7:59)
I have another question, and this is going to sound like QA.

[Speaker 1] (7:59 - 8:00)
Keep going. You're doing great.

[Speaker 2] (8:03 - 8:36)
Is there a guide on how to QA a front-end change? Because I'm sensing that if you're changing something on such a crucial, in such a crucial view, which is the drawer, it seems like a different browser should probably be the pretty important high-priority check as well? Especially given that we're kind of buying a pretty hacky way to fix this.

[Speaker 1] (8:37 - 10:57)
That's a really good question. We do have, it is in our, I want to see if I can find it. I don't trust my ability to search the GitLab docs really well.

Let's see if I can do it. Yes, yes, yes. Acceptance.

Maintainers are the DRI of assuring the acceptance criteria of a merge request is reasonably met. So part of that acceptance criteria is, like, hey, is this going to cause browser-specific issues? And there's so much here.

So you're asking a really great question because this is a very specific task of I want to QA something that touches the front-end. Like, I imagine you're almost picturing, like, a checklist of, like, let's test. Does it work in Safari?

Does it work in Firefox? Does it work in Chrome? And the answer to that is no, we don't have, like, a task list for that activity.

We more have, like, here's our requirements we're trying to meet. And so make sure everything is reasonably going to meet those requirements. And so a lot is left to discretion, which is good because we don't, we're trying to lean towards maximising our efficiency.

And I think putting human discretion in the loop is important for that. But it is very likely that that would be something worth elaborating of just a guideline for how to, how things to think about when you're wanting to smoke test. Like I just did.

If I'm wanting to smoke test just from the front-end, hey, this is reasonably okay. A guideline of steps to take is actually a really great idea. I'm going to write it down.

I need to write it down or I won't do anything about it. But I like that idea a lot. Yeah.

Thanks for bringing it up.

[Speaker 2] (10:59 - 11:37)
No worries. It's always good to have a list, like a checklist, even, to just remember the steps. But I understand, like, when pushing a change that seems to be pretty all right, you kind of feel like, okay, probably will be okay in other browser.

But if it's something as large, I would take the time. Also, it might be good to write up a bit of a guide on how to set up different browsers. I don't know if that's in place.

Help the developer with that.

[Speaker 1] (11:41 - 17:02)
Yeah, that's a really, really good point. Thanks for bringing it up. I'm realising a lot of our lists aren't, like, procedure lists of, like, you do this, then do this, then do this.

It's more like, here's our acceptance criteria lists. And I think that that's an important distinction for maybe why the lists are difficult to follow. Cool.

We have, like, a list of browsers that we support and screen sizes that we support. Yeah, yeah. So, like, we have that list, and then it's kind of up to the reviewer or whoever to interpolate that into what you're going to be reviewing for.

But I can see how that a lot can fall through the cracks through that assumptions. That's interesting. Cool.

And I had another question. Do we have anything like visual regression tests? I feel like you've asked this question before.

I say that because I think you have, and you're asking it because it's such a good question. And you're asking it because it'd be so nice to have. So we have, because doing visual regression...

No, I don't think it was you that asked that. Sorry, Andrea, I don't mean to throw you under the... I'm not trying to throw you under the bus.

Let me rephrase that. Everybody asks that question, because it is a good question. And the answer is, sort of.

For the GitLab UI, one of the big wins we get with this component library is we can create visual regression tests for these components way more efficiently and usable than doing, like, page-wide regression testing. But where things get really challenging is the devil is in those details of when all the page is interacting with each other, when all the CSS from the page, like, that causes... So that was one other really surprising thing with this.

I could have just tested this just within the GitLab UI storybook. I don't want to run into this. For some reason, in our context, with other things loading on the page, that's causing this issue.

And so, that full integration visual regression testing, we don't have really well. Yeah, I think we do have it for some components that are on the GitLab project. We do have, like, a storybook on the GitLab project.

But our intention is to try to create components that we can create these storybook snapshots of, rather than, like, taking snapshots of, like, a whole Capybara page. Because those will end up having so many false negatives, because so much changes with, like, each incremental Chrome version that gets run. And then, like, when we explored this in the past, it wasn't the cost for running and maintaining that, like, page-wide regression testing was not going to...

The cost for that wasn't outweighing the benefit. And we were really interested in trying to isolate this at the component level, but there might be more cost-effective ways to do this regression testing that we need to explore. So, it's a good thing to keep thinking about, of, like, how could we have automated patching this?

It's a really good thing to think about. There are nowadays some new tools in the market for visual regression tests that uses some machine learning capabilities to do a smarter comparison with snapshots, and also better snapshots updates and whatnot. That's so freaking fancy.

I'm out. I guess human brains are old school. That'd be cool.

Yeah, that'd be really cool. Thank you. And I think I highly recommend, at any point at GitLab, we're pretty...

I think generally our culture is very... We prioritise team-wide initiatives. So, even though we're, like, sliced to a specific group, bring up to the manager and PM of, like, hey, we should really set aside time to do this that will help our group and all of GitLab.

And those things get prioritised, and it's really good to see those initiatives happen. So, doing an investigation of using one of those tools or something like that would be really cool. Okay.

Yeah.

[Speaker 2] (17:02 - 17:07)
I have a question. Now that we're discussing... Hey, hi.

Sorry for joining.

[Speaker 1] (17:07 - 17:08)
Hey, good to see you Deepika. No, you're good.

[Speaker 2] (17:10 - 17:14)
I'm always in... It's a little late here at this time, but I just thought I'd join today after long.

[Speaker 1] (17:15 - 17:16)
Yeah, thanks for joining.

[Speaker 2] (17:17 - 17:51)
I just have, like, we started reviewing the MRs, and I just have this every time that sometimes there is a front-end label. For me, for example, Vue is... I'm okay at Vue now because it is, like, new, but I'm not good at Ruby.

So, if I get an MR, which I see that a lot of backend changes, and there is a front-end label. And I don't think that... I'll ask questions, I'll see that it runs, but I don't think I'm good enough to actually review it.

Like, I'm not... I would say, I don't know what you were to use.

[Speaker 1] (17:51 - 17:51)
Yeah.

[Speaker 2] (17:52 - 18:05)
So, sometimes I'm just forced to, like, approve it. But I know a 50% in my end that I'm not 100% satisfied with the way I've reviewed it. So, what do we do in such cases?

[Speaker 1] (18:05 - 20:11)
That is a really good question. That I'm going to actually... I think we've diverged a little bit from the MRs that are both FV and Ruby.

I'm going to diverge just a little. I think that's its own topic. So, I just opened up an MR that I recently reviewed that had both.

So, this is doing... This is shuffling around some CSS pages so that we can take what was previously being added for every single application CSS. And we could put it on just, hey, only the clusters page needs this.

So, we're moving CSS pages around. But then there's this backend change. And it's very easy for me to just be like, I have no idea what this is.

I don't know what Rails is. I don't know what this double arrow thing is. So, in those situations, and that will definitely come up, I mean, that's why we do have both the frontend and backend review.

And I am... It's okay for me to identify this is outside my area of expertise. And so, I want to make sure that someone that this is inside their area of expertise has reviewed and approved it.

So, looking back, I was like, I guess that's what we do. I've seen this before. But this is the backend maintainer, Etienne.

I don't know how to say that name. And he approved it. And I was like, okay, this is inside his domain.

He knows what he's doing. So, I don't... I'm going to keep an eye on it.

But I don't have... That's not necessarily... I will prove it knowing that, like, almost delegating, like, my trust to that expert.

Does that make sense?

[Speaker 2] (20:12 - 20:19)
Yeah. But, okay. So, sometimes, like, I'll show you an MR, which I just bought today.

[Speaker 1] (20:20 - 20:21)
Do you want to share your screen? That would be amazing.

[Speaker 2] (20:22 - 21:15)
Yeah. So, MRs, such MRs, I just put it on the back burner for late, and then I'm just not, like, happy doing it. Because, like, for example, this.

This is an MR which I see only has, like, kind of backend changes. And there's very less, I would say. Okay.

So, there are no... Just the hammer and everything. So, I don't know.

So, all the MR, I just understand this. The pyjamas component today. So, I'm just getting, like, used to all the things.

[Speaker 1] (21:16 - 21:16)
Yeah.

[Speaker 2] (21:16 - 21:26)
But a lot of things, and, yeah. But you see that a lot of, almost a lot of backend changes. And I don't know, like, good enough to, like, review it.

[Speaker 1] (21:26 - 21:54)
Yeah. And you don't have... So, I would say the way our process is, is you are not, you're not being asked to review the backend.

You should just be concerned about the changes to the HTML hammer side from the front end perspective. So, like, hammer is interesting where you do have both worlds clashing often where you have... Not clashing, but you have the backend and the frontend at the same time.

And...

[Speaker 2] (21:54 - 21:55)
Yeah.

[Speaker 1] (21:55 - 22:47)
So, from that perspective, I would... If there were, like, heavy Rails backend stuff happening on the hammer that I didn't feel like I was comfortable with, I would approve saying, like, hey, from the frontend perspective, we're not changing anything here, so I'm approving. This is good.

But can someone from the backend just confirm... Just double confirm these changes. And I think that the backend reviewers are also tasked with reviewing the backend change of the hammer.

So, I think your responsibility here is almost, like, are we changing anything to the frontend? Like, are we adding anything to the frontend? And it looks like it's not.

So, I think that's good. That's all... That's the big ask here, really.

Yeah.

[Speaker 2] (22:48 - 23:32)
But I also feel guilty about not, like, testing these, like, these kind of MRs. Like, when I just check out, for example, I got a security MR, which I had no clue about. And I was, like, what do I do with this?

I had to mirror the repo again. And I ended up just approving because I asked questions and I just got answers, like, directly. Yeah, I know.

So, is it okay to approve it like that? I just feel I'm not doing justice to the review method then. I personally...

Yeah. When I get a review, just check out, test it. That's the process that we do.

So, yeah. Just wanted to bring it out.

[Speaker 1] (23:33 - 25:03)
Yeah. Yeah. I think you highlighted, like, one of the most important things, which is just asking questions.

Like, no one is expected, other than maintainers. No one is expected to be... You don't even have to be an expert in front of it.

It's just about collaborating as someone that isn't familiar with the domain. Let's collaborate and ask questions about it. And it's really, like, that's the most important thing that can be done.

But then also, as you start to become more and more familiar with it, then you can identify, you know, the issues, maintainability issues, or even user-facing issues that might come up with certain approaches. So, that is... Like, when you first start reviewing in MARS, that will be probably difficult to find.

But you'll see maintainer comments after your approval. Yeah. And it's over time, you would want to try to see, like, oh, the maintainer found this.

Like, that's something I'm going to register in the back of my head of, like, oh, I've got to be looking out for this thing. And there's a lot of those things. So, it's also just about getting a deeper, deeper understanding of how we view and look at these things.

But, yeah, from this MR, yeah, these MRs can be a little, like, daunting of, like, oh, man, 16 files changed. Gosh. But from the front-end perspective, I'm like, ah, this is a back-end problem.

[Speaker 2] (25:06 - 25:10)
Yeah, that sounds... I'm not the only one who's feeling that way.

[Speaker 1] (25:11 - 26:11)
No, no, you're good. Yeah. Yeah, with that perspective, I would challenge all the front-enders and the back-enders, just let's try to gain some understanding of both sides of the stack.

Because we do want to understand, hey, how does the back-end work with the scope of the front-end changes that are happening? And how is the front-end working with the scope of the back-end changes that are happening? So, keeping that context in mind is really helpful.

So, even though I was kind of joking about, oh, this isn't our problem, don't worry about it. I would hesitate to draw just a thick border of, like, hey, back-end, you do your thing, we're going to do our thing. That's not going to work.

We do want to try to understand a little bit. But your expertise in no way are you expected to be an expert in Ruby and Rails and stuff. That's not needed.

Yeah. Hope that was helpful. Hey, Katia.

Yeah.

[Speaker 2] (26:12 - 26:14)
Can I just throw something in?

[Speaker 1] (26:14 - 26:14)
Yeah, please, yeah.

[Speaker 2] (26:15 - 27:03)
I'm pretty fresh on the onboarding stuff because I just started recently. And there is actually a note about this particular situation in the handbook. It basically says that if you're not comfortable reviewing a change because it's a different language, because it's, like, a little bit over your head, then basically don't feel afraid to ping someone for the review because you're not comfortable doing it yourself.

And I would recommend that as well because at the end of the day, if you approve something and it causes some drama, it will be your name on it. It was approved by you. And you don't want that because if you're not sure that you're happy with the code.

[Speaker 1] (27:04 - 27:04)
Yeah.

[Speaker 2] (27:05 - 27:29)
And also, I think, don't quote me on this particular thing, but I think I read that the files that still live in the Ruby on Rails, even the front end stuff that lives in Ruby on Rails still belongs to the back end reviewers and not the front end reviewers. I might be wrong, but I feel like that's what I read.

[Speaker 1] (27:30 - 28:18)
That's a really good, thanks for bringing it up. And that is a really good point. Yes, definitely.

Feel free to just say, I think this is outside my domain. Let me ping someone else to review it. That's an awesome thing to do.

And we do that in front end all the time, because the front end and back end too, like the scopes are so large that sometimes there's like a really detailed Apollo change and I'm like, let's see if, let's add this to Natalia's queue. She's going to be able to review this well. But to what you're saying about the, I think the HAML files are the ones that are in question of like, is this a front end or a back end asset?

Is that, Kasia, is that what you're thinking is these HAML files?

[Speaker 2] (28:19 - 28:29)
Yeah, I'll try to look it up. What I've read, just refer back to it and see if I can find a particular line, but I feel like I've read that that is still a back end consideration.

[Speaker 1] (28:29 - 29:58)
Yeah, so I would say those files are, they end up being both back end and front end, because those files can contain Ruby code. So the way that we've officially tried to sift the responsibility is the Ruby code side of those files is back end, and the front end side is front end. But I would strongly encourage every front end engineer to use those HAML files to learn Ruby and you want to get really familiar with the Ruby that intersects with those HAML files is going to be really helpful.

Yeah. Thanks for bringing that up. That was a good question.

I would also like to add that I think there is a way basically to restart the review roulette, but if you're unsure whom to suggest, so you can just spin the roulette again and just find someone. How do you do that? How do you restart it?

Do you know how to do that? Not from the top of my head, but there is this job basically that produces the danger output. And one of that part is the danger bot.

So you just restart this part, and then it should be fine-ish. Okay. But I need to double check.

Because at least.
 This file is longer than 30 minutes.
 Go Unlimited at TurboScribe.ai to transcribe files up to 10 hours long.
