Participants:
? Sarah Chen (Manager): Senior Director of Product
? Javier Morales (Direct Report): QA Lead
Date: September 22, 2025
Time: 3:00 PM - 4:00 PM
Format: Video call
Sarah: Hi Javier. How are you?
Javier: Hello Sarah. I am doing well, thank you. And you?
Sarah: I'm good, thanks. It's been a very meeting-heavy day, but productive. So, I wanted to use our time to follow up on the items from our last talk, and then see what's new on your end.
Javier: That sounds efficient. I have a few topics as well.
Sarah: Great. So, first, thank you for sending over those links. I got the automation roadmap Confluence page and the proposal for your security certification.
Javier: Yes. I sent those after our last discussion.
Sarah: I did review the automation roadmap. It's very detailed. Very thorough. It's clear you and your team have put a lot of thought into this.
Javier: Thank you. It represents many months of analysis. We are tracking our progress against it.
Sarah: I guess I'm still trying to get my head around the high-level picture. I see all the workstreams. The refactoring of UI tests. The new API tests. The framework evaluation. It's a lot. My question is still, when can we communicate a real milestone? When can I go to Mike, or to the rest of the leadership team, and say our regression time is cut by 50 percent? Or that 80 percent of critical paths are automated? I'm just not seeing the dates.
Javier: That is a difficult question. As I mentioned, the dates are not fixed. They are dependent on external factors.
Sarah: Right. You said the engineering refactoring.
Javier: Correct. We are dependent on the frontend team to add the data-testid attributes we need. Without those, our selectors are brittle. They break. We have a dependency. Our roadmap is aligned with their roadmap. If they reprioritize, then our timeline slips.
Sarah: So we are blocked.
Javier: Blocked is a strong word. I would say coupled . We are coupled to their sprint capacity. We are working with the frontend engineering manager to secure a small percentage of each sprint for this technical debt. But it is a negotiation.
Sarah: I see. It just makes it very hard for me to forecast. It feels like we are investing heavily in this big project, the automation, but I can't tell anyone when it will pay off.
Javier: It is paying off incrementally. As I noted, our API suite coverage is up 40 percent. That is a significant improvement in catching bugs before they reach the UI. It is just invisible work. It doesn't look flashy. But it is the foundation.
Sarah: I understand. I trust your technical judgement on this, Javier. I just need the so what . The story. How does 40 percent more API tests translate to business value? Does it mean we ship faster? Does it mean fewer P1s?
Javier: In theory, yes. A higher API test coverage correlates with a lower bug escape rate for business logic. It is a leading indicator. We are preventing the checkout bug before it even happens.
Sarah: Okay. Okay. Let's try to quantify that. Maybe that's the metric we should be tracking. Not just coverage , but bugs caught at API layer versus bugs caught at UI layer . Could you pull that data?
Javier: That is possible. We would need to tag our bug tickets with the detection layer. It would be a process change. But yes. We could track that.
Sarah: Okay. Let's do that. I think that would help me tell the story.
Javier: Understood. I will define the process with the team.
Sarah: Great. Thank you. And the certification? The security one? I saw the proposal. It looks good. It's a significant cost.
Javier: It is one of the premier certifications in the industry. It covers cloud architecture, penetration testing. It is very comprehensive.
Sarah: I'm not questioning the value. I'm just looking at the Q4 budget. It's tight. I'm working on it. I have to get approval from finance. So, pending . But I am supportive of it.
Javier: I understand. Thank you for looking into it.
Sarah: Of course. Okay, so hiring. What's the latest on the open SDET position? You said you had two strong candidates.
Javier: Yes. We completed the final interviews. Both were very strong. The team had a long debrief. We reached a consensus. We extended an offer to one of them last Thursday.
Sarah: That's great news, Javier. That's fantastic.
Javier: Yes. We are very hopeful. She has ten years of experience. Deep knowledge of CI/CD pipelines and performance testing. She would be a major asset.
Sarah: So has she accepted?
Javier: Not yet. She said she would let us know by tomorrow. She is considering another offer. So we are waiting.
Sarah: Okay. Well, do we have a backup? What about the second candidate?
Javier: He was also strong. But different. More of a frontend specialist. Very good with Cypress and Playwright. The team felt the first candidate, the one with the pipeline experience, was a better fit for our shift left strategy. But yes. The second candidate is our silver medalist.
Sarah: Good. Good. It's so important to have options. This market is just, it's brutal. So you'll let me know as soon as you hear?
Javier: Of course. I will send you an email the moment the recruiter pings me.
Sarah: Perfect. Okay. That's all my follow-ups. What was on your mind?
Javier: I have two topics. One is just an update. The other is more of a question. An idea.
Sarah: Okay. Let's hear the idea first.
Javier: Okay. I have been thinking a lot about our environments. Our test environments. A lot of our team's time, our drag , it comes from environment instability.
Sarah: How do you mean? Like the server is down?
Javier: Sometimes. Or the data is stale. Or a downstream service, a dependency, it is not configured correctly. Or it has the wrong version of the code. We spend, I would estimate, maybe 15 to 20 percent of our cycle time just validating the environment before we can even start testing.
Sarah: Twenty percent? That's huge. That's a whole day a week.
Javier: It is. It is a massive drain. And it is frustrating for the team. And the engineers, they feel it too. They push code, and the build fails. And it is not their code. It is the environment.
Sarah: So what's the solution? Is this a dev-ops problem? Do I need to talk to Mike's team?
Javier: That is one approach. But we are also blind. We don't have visibility. We find out when the test fails. We are reactive.
Sarah: Okay. So you want visibility .
Javier: Yes. I have an idea. A small project. I would like to build a health check dashboard . A single page that pings all of our core microservices. It checks the database, the data freshness. It validates the build versions of all the dependencies. It would give us a green or red status for each test environment. Before we run our tests.
Sarah: Huh. A health check dashboard . I like the idea. It sounds really useful.
Javier: I believe it would save us and engineering a lot of time. It would remove the guesswork. But it is not on any roadmap. It would take time. It would take resources.
Sarah: You mean it would take your team's time?
Javier: My team's time. Yes. Or I could prototype it myself. But I am not sure how to prioritize this. It is an internal tool. It does not have direct customer value .
Sarah: I see. I see the dilemma. It's infrastructure . It's internal enablement . That's a hard sell.
Javier: Yes. So I do not know what to do. Do I write a proposal? Do I just build a proof of concept in my spare time?
Sarah: I hear you, Javier. And I think the idea is smart. It really is. But my concern is focus. Right? We just spent twenty minutes talking about the automation roadmap. That is our P0. That is the big rock we must move.
Javier: I agree. It is.
Sarah: And this new dashboard project, it feels like a distraction. A side quest . Even if it helps the main quest, it is not the main quest. Do you see what I'm saying?
Javier: I do. Yes. The roadmap is the priority.
Sarah: Yes. I think we have to be ruthless about focus. I would hate for you to spend a month building this tool, and then the automation timeline slips even further.
Javier: That is a fair point. I understand.
Sarah: Let's put this on the backlog . The ideas backlog. Let's keep our powder dry on the automation plan. Let's get that to a done state. Or a better state. And then we can talk about new projects. Okay?
Javier: Okay. Yes. Understood.
Sarah: Okay. Good. Good. So what was the other topic? The update?
Javier: Yes. It is about the new mobile redesign sprint. The one that just started.
Sarah: Oh. Right. Yes. The profile and auth sprint. I know Alex is very excited about that.
Javier: Yes. It is proceeding. We are testing the stories as they are delivered to us.
Sarah: And? How's it going? Is the quality good?
Javier: The engineering quality is good. The code is clean. We are not finding many crashes or functional bugs.
Sarah: But? I hear a but in your voice.
Javier: It is just a process challenge. A requirements challenge.
Sarah: Oh? What do you mean?
Javier: The documentation is sometimes not as detailed as we would prefer.
Sarah: The documentation? You mean the user stories? Are the acceptance criteria not clear?
Javier: The acceptance criteria are written. Yes. But the product expectations, they seem to change.
Sarah: Change? How?
Javier: We will test a story. We will verify all three or four ACs . We will pass it. The ticket is green . It is QA Approved .
Sarah: Okay. That sounds good.
Javier: But then, in the sprint review. Or in an ad hoc demo. The Product Manager will look at it. And will say it is not right .
Sarah: Not right'? What does that mean? If it met the criteria?
Javier: That is the ambiguity. It feels wrong . Or the animation is too fast . Or the color is not what I was thinking . These are very subjective comments. They are not in the ACs .
Sarah: Ah. I see.
Javier: And this creates re-work. It creates churn . The ticket is re-opened. It goes back to In Progress . We have to get new requirements. Or clarified requirements. Then engineering has to re-code. And then we have to re-test. The entire story. It impacts our velocity. It impacts our morale.
Sarah: I understand. And I agree. That's not efficient. That's a process smell . So we have a requirements-definition issue.
Javier: It feels like that. Yes.
Sarah: That's feedback for Alex. But we should also formalize the handoff. Are you signing off on the tickets before they go to grooming'? Is QA part of the definition of ready'?
Javier: Yes. We are. We attend the grooming sessions. We story point the QA effort . We follow the process.
Sarah: Hmm.
Javier: It is less of a process issue at the start of the sprint. It is a feedback issue at the end of the sprint. The requirements are dynamic.
Sarah: I see. Dynamic requirements . That's just scope creep . That's what that is. And it's not fair to you or to engineering.
Javier: It makes planning very difficult.
Sarah: Okay. Let's raise this in the next cross-functional meeting. We need to emphasize that acceptance criteria must be locked before QA begins testing. We can't have this. It's inefficient. I'll mention it to Alex as well.
Javier: Understood. Thank you.
Sarah: Okay. We are at time. This was a lot. So action items . I will follow up on the certification budget . I will talk to Alex about the requirements process . You are going to implement the new bug tracking metric . And keep me posted on the candidate .
Javier: That is correct.
Sarah: And we are postponing the health dashboard idea to focus on the automation roadmap .
Javier: Yes. Understood.
Sarah: Okay. Great. This was good, Javier. Very productive .
Javier: Thank you, Sarah. Have a good rest of your week .
Sarah: You too . Bye .
Javier: Goodbye.
